{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb6uwZUzpMEg"
   },
   "source": [
    "# Classification of Wood Species based on Images\n",
    "\n",
    "The Forest Species Database – Microscopic contains 2,240 microscopic images of `112` different wood\n",
    "species. The images have been captured through microscope optics and the spatial resolution of the\n",
    "images is 1024 x 768 pixels. The total size of the data set is approx. 3.5 GB.\n",
    "\n",
    "## 0. Title\n",
    "Lappeenranta-Lahti University of Technology LUT\n",
    "\n",
    "BM20A6100 Advanced Data Analysis and Machine Learning - Luento-opetus 6.9.2021-17.12.2021\n",
    "\n",
    " \n",
    "Practical Assignment\n",
    "\n",
    "Group D: \n",
    "Mikhail Farmakovskii, stnum: `000327770`, developer; \n",
    "Daniil Kunin, stnum: `000331753`, developer.\n",
    "\n",
    "19.12.2021\n",
    "\n",
    "\n",
    "## 1. Problem\n",
    "Train a convolutional neural network (CNN), classify the images to the predetermined classes (wood species) and quantitatively evaluate the model performance\n",
    "\n",
    "## 2. Data\n",
    "https://web.inf.ufpr.br/vri/databases/forest-species-database-microscopic/\n",
    "\n",
    "## 3. Evaluation\n",
    "Quantitatively evaluate the model performance\n",
    "\n",
    "## 4. Features\n",
    "\n",
    "* There are 112 wood species, 20 images per species = 2,240 images. (112 classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4A8diK_RBb6"
   },
   "source": [
    "## Adjust workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow into jupyter\n",
    "import tensorflow as tf\n",
    "# Import Pandas into jupyter\n",
    "import pandas as pd\n",
    "# Same for numpy\n",
    "import numpy as np\n",
    "import datetime \n",
    "\n",
    "# others\n",
    "import os # access to folder\n",
    "from os import path\n",
    "\n",
    "from matplotlib.pyplot import imread # read image\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "\n",
    "from sklearn.model_selection import train_test_split # for data splitting\n",
    "from sklearn.metrics import confusion_matrix, classification_report # confusion matrix\n",
    "\n",
    "# Neural network tools\n",
    "from keras.models import Sequential # Keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense # layers\n",
    "from keras.optimizers import Adam # Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this image size if you want, default 220\n",
    "image_size = 224 # new size of image\n",
    "NUM_EPOCHS = 50 # № of epochs\n",
    "BATCH_SIZE = 50 # Define the batch size = 50. The total number of training objects presented in one batch.\n",
    "num_of_images = 2240 # Set the number of images to use for experimenting with model. Maximum - 2240\n",
    "\n",
    "# Folder adjustments\n",
    "cwd = os.getcwd()\n",
    "cwd = cwd.replace('\\\\','/')\n",
    "\n",
    "tensor_board_dir = cwd + \"/logs\" # This folder will contain logs of training\n",
    "filenames_dir = cwd + \"/data\" # 112 folders with classes here\n",
    "modeldir = cwd # The model will be saved here\n",
    "loaded_model = cwd + \"/WoodClassification.h5\" # The model will be loaded from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(folder):\n",
    "    \"\"\"\n",
    "    The function appends file paths to list\n",
    "    \"\"\"\n",
    "    dirs = os.listdir(folder) # list of folders with species\n",
    "    filenames = [] # create an empty list\n",
    "    labels = [] # list for \n",
    "    for i in range(0, len(dirs)):\n",
    "        cur_dir = str(folder + \"/\" + dirs[i] + \"/\")\n",
    "        #print(cur_dir)\n",
    "        list_of_files = os.listdir(cur_dir) # list of files in current folder\n",
    "        for j in range(0, len(list_of_files)):\n",
    "            species = \"'\" + dirs[i]  + \"'\" # get true classes\n",
    "            #print(species)\n",
    "            QQ = eval(species)\n",
    "            labels.append(QQ)\n",
    "        \n",
    "            files = \"'\" + cur_dir + str(list_of_files[j]) + \"'\"\n",
    "            q = eval(files) \n",
    "            filenames.append(q) # append image paths to list \n",
    "            \n",
    "    return filenames, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/misha/Desktop/sample_project_1/data/001 Ginkgo biloba/00101.png',\n",
       " 'C:/Users/misha/Desktop/sample_project_1/data/001 Ginkgo biloba/00102.png',\n",
       " 'C:/Users/misha/Desktop/sample_project_1/data/001 Ginkgo biloba/00103.png',\n",
       " 'C:/Users/misha/Desktop/sample_project_1/data/001 Ginkgo biloba/00104.png',\n",
       " 'C:/Users/misha/Desktop/sample_project_1/data/001 Ginkgo biloba/00105.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames, labels = get_filenames(filenames_dir)\n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001 Ginkgo biloba',\n",
       " '001 Ginkgo biloba',\n",
       " '001 Ginkgo biloba',\n",
       " '001 Ginkgo biloba',\n",
       " '001 Ginkgo biloba']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels matches the number of filenames\n"
     ]
    }
   ],
   "source": [
    "# See if number of labels matches the number of filenames\n",
    "if len(labels) == len(filenames):\n",
    "    print(\"Number of labels matches the number of filenames\")\n",
    "else:\n",
    "    print(\"Number of labels does not matches the number of filenames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['001 Ginkgo biloba', '001 Ginkgo biloba', '001 Ginkgo biloba',\n",
       "       '001 Ginkgo biloba', '001 Ginkgo biloba'], dtype='<U31')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(labels) # convert to numpy array\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['001 Ginkgo biloba', '002 Agathis becarii',\n",
       "       '003 Araucaria angustifolia', '004 Cephalotaxus drupacea',\n",
       "       '005 Cephalotaxus harringtonia'], dtype='<U31')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the unique labels values\n",
    "unique_species = np.unique(labels)\n",
    "unique_species[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_species) # 112 - number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn every label into an array of boolens\n",
    "# This code helps us to understand which class corresponds with label (True if yes, else no).\n",
    "boolean_classes = [label == unique_species for label in labels]\n",
    "boolean_classes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup x & y variables\n",
    "x = filenames\n",
    "y = boolean_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/misha/Desktop/sample_project_1/data/001 Ginkgo biloba/00101.png',\n",
       " 'C:/Users/misha/Desktop/sample_project_1/data/001 Ginkgo biloba/00102.png']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1792, 1792, 448, 448)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting\n",
    "x_train, x_val, y_train, y_val = train_test_split(x[:num_of_images],\n",
    "                                                  y[:num_of_images],\n",
    "                                                  test_size=0.2)\n",
    "\n",
    "len(x_train), len(y_train), len(x_val), len(y_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Preprocessing Images\n",
    "\n",
    "### In this section we should convert images to tensors\n",
    "`Tensors` are multi-dimensional arrays. Its type is np.array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1024, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is possible to convert pixels to array. Its shape is (768, 1024, 3)\n",
    "image = imread(filenames[0])\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.28235295, 0.20784314, 0.15294118],\n",
       "        [0.28235295, 0.19607843, 0.14509805],\n",
       "        [0.32156864, 0.19215687, 0.13333334],\n",
       "        ...,\n",
       "        [0.1254902 , 0.10980392, 0.11372549],\n",
       "        [0.09803922, 0.1254902 , 0.09803922],\n",
       "        [0.10196079, 0.12156863, 0.10588235]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for color scaling and size reshaping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(Image_path, img_size=image_size):\n",
    "    \"\"\"\n",
    "    Here we are using a Tensorflow function to process images.\n",
    "    Input: file path\n",
    "    Output: Tensor (array)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read image by using path\n",
    "    Image = tf.io.read_file(Image_path)\n",
    "    # Turn the image into numerical tensor with 3 colour channels\n",
    "    Image = tf.image.decode_png(Image, channels=3)\n",
    "    # Convert the colour channel 0-255 to 0-1 \n",
    "    Image = tf.image.convert_image_dtype(Image, tf.float32)\n",
    "    # Resize the image\n",
    "    Image = tf.image.resize(Image, size=[img_size, img_size])                                \n",
    "    return Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get image and its label\n",
    "def get_image_label(image_path, label):\n",
    "    \"\"\"\n",
    "    Function get_image_label returns the image after processing (Tensor type) & its label\n",
    "    \"\"\"\n",
    "    image = process_image(image_path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data samples\n",
    "Getting many pairs by using function `get_image_label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to return data into batches\n",
    "def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
    "    \"\"\"\n",
    "    Create batches of data. Pairs are used (tensor and true class)\n",
    "    Input: x: image path, y: true class, batch size (default 32), also for test and validation data.\n",
    "    Output: samples of data with tensors and their classes\n",
    "    \n",
    "    from_tensor_slices - creates a Dataset whose elements are slices of the given tensors.\n",
    "    The given tensors are sliced along their first dimension.\n",
    "    \n",
    "    .batch - combines consecutive elements of this dataset into batches.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "  # If the data is a test dataset (no labels)\n",
    "    if test_data:\n",
    "        print(\"Creating test data batches.......\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # \n",
    "        data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
    "        return data_batch\n",
    "\n",
    "\n",
    "  # If data is a valid dataset. Don't need to shuffle\n",
    "    elif valid_data:\n",
    "        print(\"Creating validation data batches.......\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
    "                                               tf.constant(y))) # labels\n",
    "        data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
    "        return data_batch\n",
    "\n",
    "    # this is for train data\n",
    "    else:\n",
    "        print(\"Creating training data batches.......\")\n",
    "        # Turn filepaths and labels into tensors\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(x),\n",
    "                                               tf.constant(y)))\n",
    "        # Shuffling pathnames and labels\n",
    "        data = data.shuffle(buffer_size=len(x))\n",
    "\n",
    "        data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
    "\n",
    "        return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training data batches.......\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13216/914512400.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create training and validation data batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mvalid_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13216/2436855638.py\u001b[0m in \u001b[0;36mcreate_data_batches\u001b[1;34m(x, y, batch_size, valid_data, test_data)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mdata_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_image_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[0;32m   1859\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[0;32m   1860\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[1;32m-> 1861\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1862\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   4979\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4980\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4981\u001b[1;33m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   4982\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4983\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   4216\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4218\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4219\u001b[0m     \u001b[1;31m# There is no graph to add in eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4220\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3148\u001b[0m          \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3149\u001b[0m     \"\"\"\n\u001b[1;32m-> 3150\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   3151\u001b[0m         *args, **kwargs)\n\u001b[0;32m   3152\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3114\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3115\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4193\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   4194\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4195\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4196\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4197\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4123\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4124\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4125\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4126\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4127\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    430\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[0mprogram_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProgramContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m     \u001b[0mconverted_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_actual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_entity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogram_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_verbosity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m       \u001b[0m_log_callargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_convert_actual\u001b[1;34m(entity, program_ctx)\u001b[0m\n\u001b[0;32m    272\u001b[0m                      ' try passing f.python_function instead.')\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m   \u001b[0mtransformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_TRANSPILER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogram_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m   \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_module'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, obj, user_context)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \"\"\"\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Non-function: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py\u001b[0m in \u001b[0;36mtransform_function\u001b[1;34m(self, fn, user_context)\u001b[0m\n\u001b[0;32m    488\u001b[0m           factory = _PythonFnFactory(\n\u001b[0;32m    489\u001b[0m               ctx.info.name, fn.__code__.co_freevars, self.get_extra_locals())\n\u001b[1;32m--> 490\u001b[1;33m           factory.create(\n\u001b[0m\u001b[0;32m    491\u001b[0m               nodes, ctx.namer, future_features=ctx.info.future_features)\n\u001b[0;32m    492\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_subkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, nodes, namer, inner_factory_name, outer_factory_name, future_features)\u001b[0m\n\u001b[0;32m    181\u001b[0m                                self._extra_locals.keys(), future_features)\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     module, _, source_map = loader.load_ast(\n\u001b[0m\u001b[0;32m    184\u001b[0m         nodes, include_source_map=True)\n\u001b[0;32m    185\u001b[0m     \u001b[0mouter_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouter_factory_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\loader.py\u001b[0m in \u001b[0;36mload_ast\u001b[1;34m(nodes, indentation, include_source_map, delete_on_exit)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m   \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindentation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m   \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_source\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelete_on_exit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minclude_source_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\loader.py\u001b[0m in \u001b[0;36mload_source\u001b[1;34m(source, delete_on_exit)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;34m\"\"\"Loads the given source code as a Python module.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;31m# TODO(mdan): Drop the linter verride once the CI stops running Py2.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   with tempfile.NamedTemporaryFile(  # pylint:disable=unexpected-keyword-arg\n\u001b[0m\u001b[0;32m     53\u001b[0m       mode='w', suffix='.py', delete=False, encoding='utf-8') as f:\n\u001b[0;32m     54\u001b[0m     \u001b[0mmodule_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\tempfile.py\u001b[0m in \u001b[0;36mNamedTemporaryFile\u001b[1;34m(mode, buffering, encoding, newline, suffix, prefix, dir, delete, errors)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0m_os\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mO_TEMPORARY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mkstemp_inner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         file = _io.open(fd, mode, buffering=buffering,\n",
      "\u001b[1;32m~\\Desktop\\sample_project_1\\env\\lib\\tempfile.py\u001b[0m in \u001b[0;36m_mkstemp_inner\u001b[1;34m(dir, pre, suf, flags, output_type)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tempfile.mkstemp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             \u001b[0mfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0o600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[1;32mcontinue\u001b[0m    \u001b[1;31m# try again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create training and validation data batches\n",
    "train_data = create_data_batches(x_train, y_train)\n",
    "valid_data = create_data_batches(x_val, y_val, valid_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Data Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUnction for viewing images in a data batch\n",
    "def show_25_images(images, labels):\n",
    "    \"\"\"\n",
    "    Displays a plot of 25 images and their labels from a data batch\n",
    "    \"\"\"\n",
    "  \n",
    "   # Setup the figure\n",
    "    plt.figure(figsize=(18,18))\n",
    "    # Loop through 25\n",
    "    for i in range(10):\n",
    "    # Create sublots (5 row, 5 columns)\n",
    "        ax = plt.subplot(5 , 5, i+1)\n",
    "        # Display an image\n",
    "        plt.imshow(images[i])\n",
    "        # Add the image label as the title\n",
    "        plt.title(unique_species[labels[i].argmax()])\n",
    "        # Grid lines off\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_data.as_numpy_iterator()) # inverse conversion to image\n",
    "len(train_images), len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data in a training batch\n",
    "show_25_images(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup shape to the model\n",
    "INPUT_SHAPE = [None, image_size, image_size, 3] # batch, heigh....\n",
    "\n",
    "# Setup output shape of model\n",
    "OUTPUT_SHAPE = len(unique_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(INPUT_SHAPE[1:], OUTPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model\n",
    "# model = Sequential([\n",
    "# Conv2D(16, (3, 3), activation='relu', input_shape=INPUT_SHAPE[1:]), \n",
    "# MaxPooling2D(2, 2),\n",
    "# Conv2D(32, (3, 3), activation='relu'), MaxPooling2D(2, 2),\n",
    "# MaxPooling2D(2, 2),\n",
    "# Conv2D(128, (3, 3), activation='relu'),\n",
    "# MaxPooling2D(2, 2),\n",
    "# Flatten(),\n",
    "# Dense(512, activation='relu'),\n",
    "# Dropout((0.2)),\n",
    "# Dense(512, activation='relu'),\n",
    "# Dense(112, activation='softmax')\n",
    "# ])\n",
    "\n",
    "model = Sequential([\n",
    "Conv2D(64, (1, 1), activation='relu', input_shape=INPUT_SHAPE[1:]),\n",
    "Conv2D(64, (1, 1), activation='relu'),\n",
    "MaxPooling2D(2, 2),\n",
    "    \n",
    "Conv2D(128, (1, 1), activation='relu'),\n",
    "Conv2D(128, (1, 1), activation='relu'), \n",
    "MaxPooling2D(2, 2),\n",
    "    \n",
    "    \n",
    "Conv2D(256, (1, 1), activation='relu'), \n",
    "Conv2D(256, (1, 1), activation='relu'), \n",
    "Conv2D(256, (1, 1), activation='relu'),\n",
    "MaxPooling2D(2, 2),\n",
    "\n",
    "        \n",
    "Conv2D(512, (1, 1), activation='relu'), \n",
    "Conv2D(512, (1, 1), activation='relu'), \n",
    "Conv2D(512, (1, 1), activation='relu'), \n",
    "MaxPooling2D(2, 2),\n",
    "    \n",
    "Conv2D(512, (1, 1), activation='relu'), \n",
    "Conv2D(512, (1, 1), activation='relu'), \n",
    "Conv2D(512, (1, 1), activation='relu'),  \n",
    "MaxPooling2D(2, 2),    \n",
    "   \n",
    "Flatten(),\n",
    "Dense(4096, activation='relu'),\n",
    "\n",
    "Dense(112, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "optimizer=tf.keras.optimizers.Adam(),\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tensorboard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for TensorBoard callback\n",
    "def create_tensorboard_callback(tensor_board_dir):\n",
    "    # Create a log directory for logs of training\n",
    "    logdir = os.path.join(tensor_board_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    return tf.keras.callbacks.TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save a model\n",
    "def save_model(model, modeldir, suffix=None):\n",
    "    \"\"\"\n",
    "    Saves a model in a directory \n",
    "    \"\"\"\n",
    "    model_path = modeldir + suffix + \".h5\"\n",
    "    print(f\"Saving model to: {model_path}.......\")\n",
    "    model.save(model_path)\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion to load a model\n",
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    Load a saved model\n",
    "    \"\"\"\n",
    "    print(f\"Loading saved model from: {model_path}.......\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "                                    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train\n",
    "def train_model(model,tensor_board_dir):\n",
    "    \"\"\"\n",
    "    Trains a given model and returns the trained version\n",
    "    \"\"\"\n",
    "    # Create new tensorBoard session everytime we train a model\n",
    "    tensorboard = create_tensorboard_callback(tensor_board_dir)\n",
    "  # Fit the model\n",
    "    model.fit(x=train_data, # images(tensors) and its labels(bool)\n",
    "            epochs=NUM_EPOCHS,\n",
    "            validation_data=valid_data,\n",
    "            validation_freq=1,\n",
    "            callbacks=[tensorboard])\n",
    "    save_model(model,modeldir, suffix=\"/WoodClassification\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(loaded_model):\n",
    "    model = load_model(loaded_model)\n",
    "else:\n",
    "    model = train_model(model,tensor_board_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(valid_data, verbose=1)\n",
    "model.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir tensor_board_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First prediction\n",
    "# index = 0\n",
    "# print(predictions[index])\n",
    "# print(f\"Max value (prabability of prediction 1 image): {np.max(predictions[index])}\")\n",
    "# print(f\"Sum:{np.sum(predictions[index])}\")\n",
    "# print(f\"Max index:{np.argmax(predictions[index])}\")\n",
    "# print(f\"Predicted label: {unique_species[np.argmax(predictions[index])]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_label(predictions_probabilities):\n",
    "    \"\"\"\n",
    "    Turns an array of prediciton into a labels\n",
    "    \"\"\"\n",
    "    return unique_species[np.argmax(predictions_probabilities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to unbatch\n",
    "def unbatchify(data):\n",
    "    \"\"\"\n",
    "    Takes a batched dataset of (image, label) tensors and returns separate arrays\n",
    "    of images and labels\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    # loop through unbatched data\n",
    "    for image, label in data.unbatch().as_numpy_iterator():\n",
    "        images.append(image)\n",
    "        labels.append(unique_species[np.argmax(label)])\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, val_labels = unbatchify(valid_data)\n",
    "val_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ = []\n",
    "labels_ = []\n",
    "\n",
    "# loop through unbatched data\n",
    "for image, label in valid_data.unbatch().as_numpy_iterator():\n",
    "    images_.append(image)\n",
    "    labels_.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_conf(prediction_probabilities, labels, n=1):\n",
    "    \"\"\"\n",
    "    Plus the top 10 highest predictions confidences along with the truth label for n sample.\n",
    "    \"\"\"\n",
    "\n",
    "    pred_prob, true_label = prediction_probabilities[n], labels[n]\n",
    "\n",
    "    # Get the predicted label\n",
    "    pred_label = get_pred_label(pred_prob)\n",
    "\n",
    "    # Find the top 10 prediction indexes\n",
    "    top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n",
    "\n",
    "\n",
    "    # Find the top 10 prediction confidence values\n",
    "    top_10_pred_values = pred_prob[top_10_pred_indexes]\n",
    "\n",
    "    # Find the top 10 prediction labels\n",
    "    top_10_pred_labels = unique_species[top_10_pred_indexes]\n",
    "\n",
    "    # Plotting\n",
    "    top_plot = plt.bar(np.arange(len(top_10_pred_labels)),\n",
    "                     top_10_pred_values,\n",
    "                     color=\"grey\")\n",
    "    plt.xticks(np.arange(len(top_10_pred_labels)),\n",
    "             labels=top_10_pred_labels,\n",
    "             rotation=\"vertical\")\n",
    "  \n",
    "      # Change the color of true labels. Green for true value.\n",
    "    if np.isin(true_label, top_10_pred_labels):\n",
    "        top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_conf(prediction_probabilities=predictions,\n",
    "               labels = val_labels,\n",
    "               n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(0, len(predictions)):\n",
    "    y_pred.append(unique_species[np.argmax(predictions[i])])\n",
    "y_pred[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(val_labels, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ADAML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
